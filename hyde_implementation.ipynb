{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac3c739-294c-40f0-a792-0dbeee88deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain langchain-chroma langchain-huggingface langchain-groq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a1024d-6113-44e7-9ed5-cc82087711f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae2a101-468b-47fa-a399-c6a2fd9d3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning) # to ignore langchain's deprecation warning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d60749-2930-4a93-8b4e-22910b5abf2c",
   "metadata": {},
   "source": [
    "**HyDE (Hypothetical Document Embeddings)** is an advanced method used in the context of Retrieval-Augmented Generation (RAG) applications to improve the quality of responses by enhancing the retrieval process. \n",
    "\n",
    "## What Is HyDE?\n",
    "HyDE stands for Hypothetical Document Embeddings. It is an approach that augments the process of retrieving documents for answering a user’s query. Instead of directly using the user’s query to search for relevant documents, HyDE takes an additional step of generating a hypothetical response that serves as a representation of an ideal answer. This hypothetical document is then used as the basis for retrieving real documents from a vector store, which improves the overall quality and relevance of the information fetched.\n",
    "\n",
    "## How Does HyDE Work?\n",
    "### User Query and Hypothetical Document Generation:\n",
    "\n",
    "1. When a user submits a query, HyDE first generates a hypothetical document that might be an ideal response to the question (using an LLM).\n",
    "2. Making the hypo doc is handled by the ***hyde_chain***.\n",
    "### Embedding and Retrieval:\n",
    "\n",
    "1. The generated hypothetical document is then converted into a vector embedding—a numerical representation of the document in a high-dimensional space that captures its semantic meaning.\n",
    "2. The ***retriever*** then uses this embedding to find similar documents stored in the vector store (Chroma here). These are real documents that are semantically similar to the generated hypothetical document.\n",
    "3. This process helps find documents that match the user's intent, even if the query itself is not very descriptive.\n",
    "### Combining Retrieved Context with the Query:\n",
    "\n",
    "1. After retrieving the most relevant documents, HyDE combines these documents with the original query using a prompt template to provide context for the final generation.\n",
    "2. The LLM then takes this combined context and the user’s original question to generate the final response, which is intended to be more accurate and comprehensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a4af358-988c-4382-a2f4-c7ee79093d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "\n",
    "from langchain_chroma import Chroma  # a vector database, like- FAISS, pinecone etc\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.runnables import RunnableParallel # explained where used\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "import os  # for loading the groq api token which is stored in a .env file\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea891c47-0eb5-4e1c-b118-755df3a76e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"groq_api_token.env\")\n",
    "secret_key = os.getenv('GROQ_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c163a3e-a6f9-4a97-8a26-3300f7282435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d818a5b-4f13-4fe9-8bbc-7868bd4a58e1",
   "metadata": {},
   "source": [
    "**Whats a Vector Store?**\n",
    "\n",
    "it stores the embeddings of text...simple :)\n",
    "\n",
    "**Whats Embeddings?**\n",
    "\n",
    "computers understand numbers, not words. So an embedding model is just all the words in a language and their vector(1D array) representations. U dont need to make it urself. many such models exist and u just use them.\n",
    "\n",
    "Pass the words/text/document into the model and u'll have the vector rep of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40360b3-1f1c-45cc-af40-93e8c94c6726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma(\n",
    "        collection_name=\"rag-chroma\",\n",
    "        embedding_function=HuggingFaceEmbeddings(), # the embedding model we'll use. U can use others like openaiembbedings() too.\n",
    "        persist_directory='./abcdef2',  # saves the vector_store data locally, remove if not necessary \n",
    "        )\n",
    "\n",
    "# ignore the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc03d024-8119-4395-96af-51a3b6a0b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path_1 = \"C:/Users/Lenovo/Downloads/transformers_2.pdf\"\n",
    "pdf_path_2 = \"C:/Users/Lenovo/Downloads/unsupervisedL_forRAG.pdf\"\n",
    "pdf_path_3 = \"C:/Users/Lenovo/Downloads/NIPS-2017-attention-is-all-you-need-Paper.pdf\"\n",
    "# pdf_path_4 = \"...\"\n",
    "# pdf_path_5 = \"...\"\n",
    "\n",
    "doc_paths=[pdf_path_1,pdf_path_2, pdf_path_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c48bf64-255a-4510-81e9-b6037a231722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader # for loading the text of a pdf doc\n",
    "\n",
    "documents = []  # intialize an empty list\n",
    "\n",
    "for docs in doc_paths:\n",
    "    loader = PyPDFLoader(docs)\n",
    "    pages = loader.load_and_split() # chunking(dividing) a pdf into pages\n",
    "    for page in pages:\n",
    "        documents.append(page) # storing the chunked documents here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ca1071-f064-49e0-8925-3cf9aa26ab0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'C:/Users/Lenovo/Downloads/transformers_2.pdf', 'page': 0}, page_content='An Introduction to Transformers\\nRichard E. Turner\\nDepartment of Engineering, University of Cambridge, UK\\nMicrosoft Research, Cambridge, UK\\nret26@cam.ac.uk\\nAbstract. The transformer is a neural network component that can be used to learn useful represen-\\ntations of sequences or sets of data-points [Vaswani et al., 2017]. The transformer has driven recent\\nadvances in natural language processing [Devlin et al., 2019], computer vision [Dosovitskiy et al., 2021],\\nand spatio-temporal modelling [Bi et al., 2022]. There are many introductions to transformers, but most\\ndo not contain precise mathematical descriptions of the architecture and the intuitions behind the design\\nchoices are often also missing.1Moreover, as research takes a winding path, the explanations for the\\ncomponents of the transformer can be idiosyncratic. In this note we aim for a mathematically precise,\\nintuitive, and clean description of the transformer architecture. We will not discuss training as this is\\nrather standard. We assume that the reader is familiar with fundamental topics in machine learning\\nincluding multi-layer perceptrons, linear transformations, softmax functions and basic probability.\\n1See Phuong and Hutter [2022] for an exception to this.arXiv:2304.10557v5  [cs.LG]  8 Feb 2024')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0] # just to check if the documents are chunked properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e2f29-89e8-4cb5-a5e0-ece99dce7ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73565253-ca6b-4c45-90bd-344ddcd37717",
   "metadata": {},
   "source": [
    "**UUID - Universally Unique Identifier**\n",
    "*uuid4()* ensures that each document added to the vector store has a unique, random ID, making it easier to manage and retrieve the documents without ID conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eccfae1-f60e-4020-8cdd-2814722c355c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['22ba40e9-13e2-43f0-8c5a-8b3cfc51f273',\n",
       " '7fc831b5-156a-4847-9be4-28e3aac15cba',\n",
       " 'b0268eb4-9c78-41ff-af18-ee683119a2cd',\n",
       " '32b3f4ca-40b4-48ce-b078-dfcbe5b72461',\n",
       " '842b93ee-3f8c-4fa8-abdc-3f58c23d9208',\n",
       " 'c7872330-60b9-4037-8976-7feb2a9dc5e6',\n",
       " '2026c305-e939-4800-ac02-79fd943d1651',\n",
       " '6d93cc0d-fe40-497d-bc7c-5b43c047316a',\n",
       " '312feebd-96bd-49b6-a48c-e4544bc858f7',\n",
       " 'c9e0d4e1-f59c-499e-b5ee-85a217f4d74d',\n",
       " '0e801212-866a-4b17-a9c5-39e09f588a77',\n",
       " '7f616b07-34e1-4b62-a027-374bd1770e7e',\n",
       " '06d6a087-7314-4481-a9a4-6d6b8358409b',\n",
       " '79905460-001a-4cf1-b3a4-69f40f0a98ff',\n",
       " 'cefb95d7-434c-4052-ae4e-14cd60f350cf',\n",
       " '1f5eca0c-0ea2-4e11-a5f9-1c376cbd5cec',\n",
       " 'cf1187fb-7a58-48df-80d0-bcfe14257a31',\n",
       " '820bbac2-25cb-400b-85b8-b9bcc0968e19',\n",
       " '59254932-c76c-47c3-bf04-0bdc3885b17e',\n",
       " '3ad75a6f-ace7-4f73-bcc4-0165c1a3110e',\n",
       " 'c38de721-e5d9-460b-ac1f-dae5e5201c2e',\n",
       " 'f6bf0fad-09d7-483e-ad26-e608655478dc',\n",
       " 'bd55affb-b6f7-4b24-a12d-f96ae0aae308',\n",
       " 'c8714188-ca2a-44d9-be9a-2491186eef79',\n",
       " 'a6a2b2ba-1b3c-4862-a13e-24722be83f04',\n",
       " '1608ce38-7972-4719-80e1-01d27f6ccc3c',\n",
       " '4b65172e-ef22-49bf-857f-ddcf652ccdcf',\n",
       " '413c23d5-a3ea-49a8-ac89-3fe2d8b40d02',\n",
       " 'bf281671-088d-42e4-8b13-b972454fd6bb',\n",
       " '4e015980-2246-4158-ad6d-ed8d401ca889',\n",
       " 'd0c697dc-8459-4d4f-8780-d2204525d2da']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))] \n",
    "vector_store.add_documents(documents=documents, ids=uuids) # generated UUIDs are passed to assign a unique id to each document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c973535-4f52-441a-9435-6021fdec7b92",
   "metadata": {},
   "source": [
    "**What is a Retriever?**\n",
    "\n",
    "A retriever is a component that helps find relevant documents from a collection based on a given query. The retriever is used to search the vector store (which stores documents as vector embeddings) to find and return the documents that are most similar or relevant to the passed query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c08b3d9-ec3e-4052-9b11-a74a1ef588de",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce2b1e2f-bd2e-4fd2-8391-6804f2dfd1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f253452-f179-4f49-8666-b12eccc4de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "model = ChatGroq(temperature=0, groq_api_key=secret_key, model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7da111e0-1b74-4564-9fe3-d9fbe3b3dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query transformation chain\n",
    "# This prompts the llm to make the hypothetical document\n",
    "hyde_template = \"\"\"Please write a passage to answer the question \n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "\n",
    "hyde_prompt = PromptTemplate.from_template(hyde_template)\n",
    "hyde_chain = hyde_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383020e-90e3-4fca-8152-9c40af109899",
   "metadata": {},
   "source": [
    "**What is RunnableParallel()**\n",
    "\n",
    "It is a utility from the Langchain library that allows you to perform multiple actions or operations(runnables) simultaneously, combining their results into one structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89b07ef9-b212-45c8-9331-7702f2f50876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG chain\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            # Generate a hypothetical document and then pass it to the retriever\n",
    "            \"context\": hyde_chain | retriever,  # hyde_chain -> retriver ->(passed as) \"CONTEXT\"\n",
    "            \"question\": lambda x: x[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5d97e-b350-4115-a580-a8feaca4cc7f",
   "metadata": {},
   "source": [
    "**FLOW :**\n",
    "\n",
    "question -> chain **[** *hyde_chain **(** hyde_template | model | StrOutputParser() **)** -> retriever -> prompt -> model -> StrOutputParser()* **]** -> answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89da43dd-679f-49e4-a78b-7c283e403c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input type for the chain using Pydantic BaseModel\n",
    "class ChainInput(BaseModel):\n",
    "    question: str\n",
    "\n",
    "chain = chain.with_types(input_type=ChainInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8253dd14-5701-4976-8dae-933a312c1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = ChainInput(question=\"what are encoder stacks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8139f065-d14b-4f96-aef8-e1753d27afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for deleting the vector store.\n",
    "# vector_store.delete(ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdd1ae07-68bd-4be8-b9cb-5016a347cde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what are encoder stacks?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what are encoder stacks?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what are encoder stacks?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what are encoder stacks?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Please write a passage to answer the question \\nQuestion: what are encoder stacks?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what are encoder stacks?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what are encoder stacks?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatGroq] [2.54s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Here is a passage that answers the question:\\n\\nAn encoder stack is a crucial component in the field of robotics and computer vision, particularly in applications involving object manipulation, grasping, and tracking. In essence, an encoder stack is a combination of multiple encoders, which are sensors that convert mechanical motion into electrical signals, stacked together to provide precise and accurate measurements of an object's position, orientation, and movement.\\n\\nEach encoder in the stack measures a specific aspect of the object's motion, such as its rotation, translation, or angular displacement. By combining the outputs of multiple encoders, the encoder stack can provide a more comprehensive and accurate picture of the object's movement, allowing for more precise control and manipulation. This is particularly useful in applications where high accuracy and precision are critical, such as in robotic arms, CNC machines, and autonomous vehicles.\\n\\nEncoder stacks can be customized to meet the specific requirements of a particular application, with different types of encoders being used depending on the desired level of precision and the type of motion being measured. For example, optical encoders may be used for high-precision applications, while magnetic encoders may be used for applications requiring higher robustness and reliability. Overall, encoder stacks play a vital role in enabling precise and accurate motion control in a wide range of applications.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Here is a passage that answers the question:\\n\\nAn encoder stack is a crucial component in the field of robotics and computer vision, particularly in applications involving object manipulation, grasping, and tracking. In essence, an encoder stack is a combination of multiple encoders, which are sensors that convert mechanical motion into electrical signals, stacked together to provide precise and accurate measurements of an object's position, orientation, and movement.\\n\\nEach encoder in the stack measures a specific aspect of the object's motion, such as its rotation, translation, or angular displacement. By combining the outputs of multiple encoders, the encoder stack can provide a more comprehensive and accurate picture of the object's movement, allowing for more precise control and manipulation. This is particularly useful in applications where high accuracy and precision are critical, such as in robotic arms, CNC machines, and autonomous vehicles.\\n\\nEncoder stacks can be customized to meet the specific requirements of a particular application, with different types of encoders being used depending on the desired level of precision and the type of motion being measured. For example, optical encoders may be used for high-precision applications, while magnetic encoders may be used for applications requiring higher robustness and reliability. Overall, encoder stacks play a vital role in enabling precise and accurate motion control in a wide range of applications.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 261,\n",
      "                \"prompt_tokens\": 29,\n",
      "                \"total_tokens\": 290,\n",
      "                \"completion_time\": 0.745714286,\n",
      "                \"prompt_time\": 0.004106153,\n",
      "                \"queue_time\": 0.009385247,\n",
      "                \"total_time\": 0.749820439\n",
      "              },\n",
      "              \"model_name\": \"llama3-70b-8192\",\n",
      "              \"system_fingerprint\": \"fp_87cbfbbc4d\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-e01a61f7-3b6f-4179-a6c0-e715d54cae76-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 29,\n",
      "              \"output_tokens\": 261,\n",
      "              \"total_tokens\": 290\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 261,\n",
      "      \"prompt_tokens\": 29,\n",
      "      \"total_tokens\": 290,\n",
      "      \"completion_time\": 0.745714286,\n",
      "      \"prompt_time\": 0.004106153,\n",
      "      \"queue_time\": 0.009385247,\n",
      "      \"total_time\": 0.749820439\n",
      "    },\n",
      "    \"model_name\": \"llama3-70b-8192\",\n",
      "    \"system_fingerprint\": \"fp_87cbfbbc4d\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Here is a passage that answers the question:\\n\\nAn encoder stack is a crucial component in the field of robotics and computer vision, particularly in applications involving object manipulation, grasping, and tracking. In essence, an encoder stack is a combination of multiple encoders, which are sensors that convert mechanical motion into electrical signals, stacked together to provide precise and accurate measurements of an object's position, orientation, and movement.\\n\\nEach encoder in the stack measures a specific aspect of the object's motion, such as its rotation, translation, or angular displacement. By combining the outputs of multiple encoders, the encoder stack can provide a more comprehensive and accurate picture of the object's movement, allowing for more precise control and manipulation. This is particularly useful in applications where high accuracy and precision are critical, such as in robotic arms, CNC machines, and autonomous vehicles.\\n\\nEncoder stacks can be customized to meet the specific requirements of a particular application, with different types of encoders being used depending on the desired level of precision and the type of motion being measured. For example, optical encoders may be used for high-precision applications, while magnetic encoders may be used for applications requiring higher robustness and reliability. Overall, encoder stacks play a vital role in enabling precise and accurate motion control in a wide range of applications.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [3.03s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [3.04s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the question based only on the following context:\\n[Document(metadata={'page': 1, 'source': 'C:/Users/Lenovo/Downloads/NIPS-2017-attention-is-all-you-need-Paper.pdf'}, page_content='[9], consuming the previously generated symbols as additional input when generating the next.\\\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\\\nrespectively.\\\\n3.1 Encoder and Decoder Stacks\\\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\\\n2'), Document(metadata={'page': 1, 'source': 'C:/Users/Lenovo/Downloads/NIPS-2017-attention-is-all-you-need-Paper.pdf'}, page_content='[9], consuming the previously generated symbols as additional input when generating the next.\\\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\\\nrespectively.\\\\n3.1 Encoder and Decoder Stacks\\\\nEncoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\\\\nsub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\\\\n2'), Document(metadata={'page': 9, 'source': 'C:/Users/Lenovo/Downloads/transformers_2.pdf'}, page_content='R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neu-\\\\nral Information Processing Systems , volume 30. Curran Associates, Inc.,\\\\n2017. URL https://proceedings.neurips.cc/paper_files/paper/\\\\n2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf .\\\\nK. Wu, H. Peng, M. Chen, J. Fu, and H. Chao. Rethinking and improv-\\\\ning relative position encoding for vision transformer. In 2021 IEEE/CVF\\\\nInternational Conference on Computer Vision (ICCV) , pages 10013–10021,\\\\nLos Alamitos, CA, USA, oct 2021. IEEE Computer Society. doi: 10.1109/\\\\nICCV48922.2021.00988 . URL https://doi.ieeecomputersociety.org/\\\\n10.1109/ICCV48922.2021.00988 .\\\\nRuibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing,\\\\nHuishuai Zhang, Yanyan Lan, Liwei Wang, and Tieyan Liu. On layer normal-\\\\nization in the transformer architecture. In Hal Daumé III and Aarti Singh,\\\\neditors,Proceedings of the 37th International Conference on Machine Learn-\\\\ning, volume 119 of Proceedings of Machine Learning Research , pages 10524–\\\\n10533. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/\\\\nv119/xiong20b.html .\\\\n9'), Document(metadata={'page': 9, 'source': 'C:/Users/Lenovo/Downloads/transformers_2.pdf'}, page_content='R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neu-\\\\nral Information Processing Systems , volume 30. Curran Associates, Inc.,\\\\n2017. URL https://proceedings.neurips.cc/paper_files/paper/\\\\n2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf .\\\\nK. Wu, H. Peng, M. Chen, J. Fu, and H. Chao. Rethinking and improv-\\\\ning relative position encoding for vision transformer. In 2021 IEEE/CVF\\\\nInternational Conference on Computer Vision (ICCV) , pages 10013–10021,\\\\nLos Alamitos, CA, USA, oct 2021. IEEE Computer Society. doi: 10.1109/\\\\nICCV48922.2021.00988 . URL https://doi.ieeecomputersociety.org/\\\\n10.1109/ICCV48922.2021.00988 .\\\\nRuibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen Xing,\\\\nHuishuai Zhang, Yanyan Lan, Liwei Wang, and Tieyan Liu. On layer normal-\\\\nization in the transformer architecture. In Hal Daumé III and Aarti Singh,\\\\neditors,Proceedings of the 37th International Conference on Machine Learn-\\\\ning, volume 119 of Proceedings of Machine Learning Research , pages 10524–\\\\n10533. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/\\\\nv119/xiong20b.html .\\\\n9')]\\n\\nQuestion: what are encoder stacks?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatGroq] [562ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"According to the context, the encoder stack is composed of a stack of N=6 identical layers. Each layer has two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected layer.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"According to the context, the encoder stack is composed of a stack of N=6 identical layers. Each layer has two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected layer.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 46,\n",
      "                \"prompt_tokens\": 1133,\n",
      "                \"total_tokens\": 1179,\n",
      "                \"completion_time\": 0.131428571,\n",
      "                \"prompt_time\": 0.044516042,\n",
      "                \"queue_time\": 0.005265567999999998,\n",
      "                \"total_time\": 0.175944613\n",
      "              },\n",
      "              \"model_name\": \"llama3-70b-8192\",\n",
      "              \"system_fingerprint\": \"fp_7ab5f7e105\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-ad788845-abb8-48b2-a105-7bbeb624e54e-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 1133,\n",
      "              \"output_tokens\": 46,\n",
      "              \"total_tokens\": 1179\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 46,\n",
      "      \"prompt_tokens\": 1133,\n",
      "      \"total_tokens\": 1179,\n",
      "      \"completion_time\": 0.131428571,\n",
      "      \"prompt_time\": 0.044516042,\n",
      "      \"queue_time\": 0.005265567999999998,\n",
      "      \"total_time\": 0.175944613\n",
      "    },\n",
      "    \"model_name\": \"llama3-70b-8192\",\n",
      "    \"system_fingerprint\": \"fp_7ab5f7e105\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the context, the encoder stack is composed of a stack of N=6 identical layers. Each layer has two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected layer.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [3.60s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the context, the encoder stack is composed of a stack of N=6 identical layers. Each layer has two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected layer.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain # only for langchain.debug if u dont wanna use the debug feature, remove this.\n",
    "\n",
    "langchain.debug=True # just for visualizing the program flow.\n",
    "result1 = chain.invoke(user_input.dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c52bb7c0-fbe0-40d8-bfa7-7a1377683002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the context, the encoder stack is composed of a stack of N=6 identical layers. Each layer has two sub-layers: a multi-head self-attention mechanism and a simple, position-wise fully connected layer.\n"
     ]
    }
   ],
   "source": [
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c5303e-e318-418e-86f1-1ad41ef23bb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is K means algorithm?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is K means algorithm?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is K means algorithm?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is K means algorithm?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Please write a passage to answer the question \\nQuestion: what is K means algorithm?\\nPassage:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"what is K means algorithm?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"what is K means algorithm?\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > llm:ChatGroq] [1.47s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Here is a passage that answers the question:\\n\\nThe K-means algorithm is a type of unsupervised machine learning algorithm that is used for clustering data. Clustering is a process of grouping similar objects or data points into clusters based on their characteristics or features. In K-means clustering, the algorithm partitions the data into K clusters, where K is a user-defined parameter that represents the number of clusters desired. The algorithm works by iteratively updating the centroids of the clusters and reassigning the data points to the cluster with the closest centroid. The centroids are calculated as the mean of all the data points in a cluster, hence the name K-means. The algorithm stops when the centroids no longer change significantly or a stopping criterion is reached. The resulting clusters are typically dense regions of data points that are similar to each other and distinct from data points in other clusters. K-means is a popular clustering algorithm due to its simplicity, efficiency, and effectiveness in many applications, including customer segmentation, image compression, and anomaly detection.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Here is a passage that answers the question:\\n\\nThe K-means algorithm is a type of unsupervised machine learning algorithm that is used for clustering data. Clustering is a process of grouping similar objects or data points into clusters based on their characteristics or features. In K-means clustering, the algorithm partitions the data into K clusters, where K is a user-defined parameter that represents the number of clusters desired. The algorithm works by iteratively updating the centroids of the clusters and reassigning the data points to the cluster with the closest centroid. The centroids are calculated as the mean of all the data points in a cluster, hence the name K-means. The algorithm stops when the centroids no longer change significantly or a stopping criterion is reached. The resulting clusters are typically dense regions of data points that are similar to each other and distinct from data points in other clusters. K-means is a popular clustering algorithm due to its simplicity, efficiency, and effectiveness in many applications, including customer segmentation, image compression, and anomaly detection.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 207,\n",
      "                \"prompt_tokens\": 30,\n",
      "                \"total_tokens\": 237,\n",
      "                \"completion_time\": 0.591428571,\n",
      "                \"prompt_time\": 0.003955329,\n",
      "                \"queue_time\": 0.010356661,\n",
      "                \"total_time\": 0.5953839\n",
      "              },\n",
      "              \"model_name\": \"llama3-70b-8192\",\n",
      "              \"system_fingerprint\": \"fp_2f30b0b571\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a02e316b-72f2-44f1-9909-0fb56caa3f26-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 30,\n",
      "              \"output_tokens\": 207,\n",
      "              \"total_tokens\": 237\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 207,\n",
      "      \"prompt_tokens\": 30,\n",
      "      \"total_tokens\": 237,\n",
      "      \"completion_time\": 0.591428571,\n",
      "      \"prompt_time\": 0.003955329,\n",
      "      \"queue_time\": 0.010356661,\n",
      "      \"total_time\": 0.5953839\n",
      "    },\n",
      "    \"model_name\": \"llama3-70b-8192\",\n",
      "    \"system_fingerprint\": \"fp_2f30b0b571\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence > parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"Here is a passage that answers the question:\\n\\nThe K-means algorithm is a type of unsupervised machine learning algorithm that is used for clustering data. Clustering is a process of grouping similar objects or data points into clusters based on their characteristics or features. In K-means clustering, the algorithm partitions the data into K clusters, where K is a user-defined parameter that represents the number of clusters desired. The algorithm works by iteratively updating the centroids of the clusters and reassigning the data points to the cluster with the closest centroid. The centroids are calculated as the mean of all the data points in a cluster, hence the name K-means. The algorithm stops when the centroids no longer change significantly or a stopping criterion is reached. The resulting clusters are typically dense regions of data points that are similar to each other and distinct from data points in other clusters. K-means is a popular clustering algorithm due to its simplicity, efficiency, and effectiveness in many applications, including customer segmentation, image compression, and anomaly detection.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question> > chain:RunnableSequence] [1.95s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<context,question>] [1.95s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the question based only on the following context:\\n[Document(metadata={'page': 0, 'source': 'C:/Users/Lenovo/Downloads/unsupervisedL_forRAG.pdf'}, page_content='Unsupervised Learning in Machine Learning  \\\\nUnsupervised learning is a powerful branch of machine learning where the model learns from data \\\\nwithout any labeled outputs or predeﬁned categories. Unlike supervised learning, where models \\\\nlearn by example through labeled training data, unsupervised learning deals with data that lacks \\\\nlabels. The goal in unsupervised learning is to uncover the underlying pa Ʃerns, structures, or \\\\ngroupings within the data, making it ideal for exploratory data analysis. This approach is par Ɵcularly \\\\nuseful in situa Ɵons where manual labeling of data is either infeasible or too costly. Common \\\\napplicaƟons of unsupervised learning include clustering, anomaly detec Ɵon, and dimensionality \\\\nreducƟon, and it is o Ōen applied in areas like market segmenta Ɵon, image processing, an d \\\\nrecommenda Ɵon systems.  \\\\nOne of the most widely used techniques in unsupervised learning is clustering , a process that \\\\ninvolves grouping data points based on their similarity. Clustering is a fundamental unsupervised \\\\nlearning method that divides data into several groups (or clusters), ensuring that data points within a \\\\ncluster are more similar to each other than to those in other clusters. The clustering approach is \\\\npopular in various ﬁelds, including customer segmenta Ɵon, where businesses use it to iden Ɵfy \\\\ngroups of customers with similar behaviors, and in biology, where it helps in categorizing diﬀerent \\\\nspecies based on gene Ɵc similariƟes. Clustering is also applied in image and text analysis to group \\\\nsimilar content, aiding in recommenda Ɵon systems and data categoriza Ɵon. The challenge with \\\\nclustering lies in deﬁning similarity, which o Ōen depen ds on the context and the speciﬁc \\\\nrequirements of the applica Ɵon. \\\\nK-means clustering  is one of the most popular clustering techniques in unsupervised learning. The \\\\n\\\"k\\\" in k-means refers to the number of clusters into which the data is divided. The process begins \\\\nwith the algorithm selec Ɵng “k” random points as the ini Ɵal centroids, whic h serve as the center of \\\\neach cluster. Each data point is then assigned to the nearest centroid, forming a cluster. A Ōer \\\\nassigning all data points, the centroids are recalculated based on the mean of the points within each \\\\ncluster. This itera Ɵve process con Ɵnues unƟl the centroids no longer change signiﬁcantly, indica Ɵng \\\\nthat the clusters are stable. K-means clustering is widely used due to its simplicity and eﬃciency, \\\\nmaking it suitable for large datasets. However, it has limita Ɵons, including sensi Ɵvity to the ini Ɵal \\\\nchoice of centroids and diﬃculty in determining the op Ɵmal number of clusters, o Ōen requiring \\\\nmethods like the elbow method to assess cluster validity. \\\\nAnother key unsupervised learning technique is hierarchical clustering , which creates a tree-like \\\\nstructure of clusters. Hierarchical clustering can be either agglomera Ɵve (boƩom-up) or divisive (top-\\\\ndown). In agglomera Ɵve clustering, each data point starts as its own cluster, and clusters are \\\\nprogressively merged based on their similarity. In contrast, divisive clustering begins with a single \\\\nlarge cluster that is recursively split un Ɵl each data point is in its own cluster. The result of \\\\nhierarchical clustering is a dendrogram, a tree-like diagram that illustrates the m erging or spli ƫng \\\\nprocess and provides insight into the data’s structure. Hierarchical clustering is o Ōen used when the \\\\ngoal is to understand data hierarchy, such as organizing documents into subcategories within larger \\\\ncategories. Unlike k-means, hierarchical clustering does not require the number of clusters to be \\\\nspeciﬁed in advance, but it can be computa Ɵonally intensive for large datasets.  \\\\nDimensionality reduc Ɵon is another essen Ɵal technique in unsupervised learning, used to reduce \\\\nthe number of variables in a dataset while preserving its structure and rela Ɵonships. High -'), Document(metadata={'page': 0, 'source': 'C:/Users/Lenovo/Downloads/unsupervisedL_forRAG.pdf'}, page_content='Unsupervised Learning in Machine Learning  \\\\nUnsupervised learning is a powerful branch of machine learning where the model learns from data \\\\nwithout any labeled outputs or predeﬁned categories. Unlike supervised learning, where models \\\\nlearn by example through labeled training data, unsupervised learning deals with data that lacks \\\\nlabels. The goal in unsupervised learning is to uncover the underlying pa Ʃerns, structures, or \\\\ngroupings within the data, making it ideal for exploratory data analysis. This approach is par Ɵcularly \\\\nuseful in situa Ɵons where manual labeling of data is either infeasible or too costly. Common \\\\napplicaƟons of unsupervised learning include clustering, anomaly detec Ɵon, and dimensionality \\\\nreducƟon, and it is o Ōen applied in areas like market segmenta Ɵon, image processing, an d \\\\nrecommenda Ɵon systems.  \\\\nOne of the most widely used techniques in unsupervised learning is clustering , a process that \\\\ninvolves grouping data points based on their similarity. Clustering is a fundamental unsupervised \\\\nlearning method that divides data into several groups (or clusters), ensuring that data points within a \\\\ncluster are more similar to each other than to those in other clusters. The clustering approach is \\\\npopular in various ﬁelds, including customer segmenta Ɵon, where businesses use it to iden Ɵfy \\\\ngroups of customers with similar behaviors, and in biology, where it helps in categorizing diﬀerent \\\\nspecies based on gene Ɵc similariƟes. Clustering is also applied in image and text analysis to group \\\\nsimilar content, aiding in recommenda Ɵon systems and data categoriza Ɵon. The challenge with \\\\nclustering lies in deﬁning similarity, which o Ōen depen ds on the context and the speciﬁc \\\\nrequirements of the applica Ɵon. \\\\nK-means clustering  is one of the most popular clustering techniques in unsupervised learning. The \\\\n\\\"k\\\" in k-means refers to the number of clusters into which the data is divided. The process begins \\\\nwith the algorithm selec Ɵng “k” random points as the ini Ɵal centroids, whic h serve as the center of \\\\neach cluster. Each data point is then assigned to the nearest centroid, forming a cluster. A Ōer \\\\nassigning all data points, the centroids are recalculated based on the mean of the points within each \\\\ncluster. This itera Ɵve process con Ɵnues unƟl the centroids no longer change signiﬁcantly, indica Ɵng \\\\nthat the clusters are stable. K-means clustering is widely used due to its simplicity and eﬃciency, \\\\nmaking it suitable for large datasets. However, it has limita Ɵons, including sensi Ɵvity to the ini Ɵal \\\\nchoice of centroids and diﬃculty in determining the op Ɵmal number of clusters, o Ōen requiring \\\\nmethods like the elbow method to assess cluster validity. \\\\nAnother key unsupervised learning technique is hierarchical clustering , which creates a tree-like \\\\nstructure of clusters. Hierarchical clustering can be either agglomera Ɵve (boƩom-up) or divisive (top-\\\\ndown). In agglomera Ɵve clustering, each data point starts as its own cluster, and clusters are \\\\nprogressively merged based on their similarity. In contrast, divisive clustering begins with a single \\\\nlarge cluster that is recursively split un Ɵl each data point is in its own cluster. The result of \\\\nhierarchical clustering is a dendrogram, a tree-like diagram that illustrates the m erging or spli ƫng \\\\nprocess and provides insight into the data’s structure. Hierarchical clustering is o Ōen used when the \\\\ngoal is to understand data hierarchy, such as organizing documents into subcategories within larger \\\\ncategories. Unlike k-means, hierarchical clustering does not require the number of clusters to be \\\\nspeciﬁed in advance, but it can be computa Ɵonally intensive for large datasets.  \\\\nDimensionality reduc Ɵon is another essen Ɵal technique in unsupervised learning, used to reduce \\\\nthe number of variables in a dataset while preserving its structure and rela Ɵonships. High -'), Document(metadata={'page': 2, 'source': 'C:/Users/Lenovo/Downloads/unsupervisedL_forRAG.pdf'}, page_content='**Dimensionality reduc Ɵon** methods also play a cri Ɵcal role in data preprocessing, as they allow \\\\nmachine learning algorithms to perform eﬃciently on complex datasets by reducing unnecessary \\\\nnoise and redundancy. In genomics, for example, data o Ōen contains thousands of gene Ɵc markers, \\\\nwhich can be computa Ɵonally prohibi Ɵve. Dimensionality reduc Ɵon methods like PCA help by \\\\ncondensing the data into a manageable form that retains essen Ɵal informa Ɵon, thus facilita Ɵng the \\\\ndiscovery of underlying pa Ʃerns in biological data. Addi Ɵonally, in image recogni Ɵon, dimensionality \\\\nreducƟon aids in compressing large pixel -based data, which not only speeds up the training process \\\\nfor models but also improves the model\\\\'s generaliza Ɵon by removing irrelevant  features. \\\\n \\\\nDespite their advantages, unsupervised learning techniques have limita Ɵons. For clustering \\\\nalgorithms, deﬁning \\\"similarity\\\" is inherently subjec Ɵve and varies based on the speciﬁc data and the \\\\nintended applica Ɵon. For instance, the Euclidean distance metric used in k-means may not be \\\\nsuitable for all types of data, especially in high-dimensional or sparse datasets. Clustering techniques \\\\nare also sensi Ɵve to data scaling; if features are not standardized, clusters may be biased toward \\\\nfeatures with lar ger values. Addi Ɵonally, some clustering algorithms, like k -means, assume that \\\\nclusters are spherical and evenly distributed, which is o Ōen not the case in real -world data. These \\\\nlimitaƟons require careful data preprocessing and parameter tuning to ensu re that the results are \\\\nmeaningful. \\\\n \\\\nAnother challenge with unsupervised learning is the **interpretability of results**. Unlike supervised \\\\nlearning, where model predic Ɵons can be directly compared to true labels, the output of \\\\nunsupervised learning algorithms can be ambiguous and harder to explain. For instance, when \\\\nclustering data, it is o Ōen necessary to examine each cluster’s characteris Ɵcs manually to interpret \\\\nthe results, which can be Ɵme-consuming for large datasets. In dimensionality reduc Ɵon, while \\\\ntechniques like PCA provide insights into the principal components, they do not always reveal the \\\\nspeciﬁc variables responsible for variance, making it challenging to link the results back to \\\\ninterpretable features. \\\\n \\\\nHowever, advances in unsupervised learning con Ɵnue to address these challenges. Hybrid \\\\napproaches that combine supervised and unsupervised learning, such as **semi-supervised \\\\nlearning**, allow models to learn from both labeled and unlabeled data. This app roach is par Ɵcularly \\\\nbeneﬁcial in scenarios where a small por Ɵon of labeled data is available but insuﬃcient for fully \\\\nsupervised training. Addi Ɵonally, new clustering algorithms, such as **density -based spa Ɵal \\\\nclustering of applica Ɵons with noise (DBSCAN)**, can form arbitrarily shaped clusters and iden Ɵfy \\\\noutliers, providing more ﬂexibility than tradi Ɵonal k-means clustering. DBSCAN is especially useful for \\\\ndetecƟng clusters in data with noise, as it separates dense clusters from sparser regio ns in the \\\\ndataset. \\\\n \\\\nUnsupervised learning is also evolving through the integra Ɵon of deep learning techniques. \\\\n**Autoencoders**, for example, are neural networks designed for dimensionality reduc Ɵon. These \\\\nnetworks are trained to compress data into a lower-dimensional repre sentaƟon and then reconstruct \\\\nthe data from this compressed form. Autoencoders have become valuable in anomaly detec Ɵon and \\\\nimage processing, where they are used to learn compressed representa Ɵons of images or detect'), Document(metadata={'page': 2, 'source': 'C:/Users/Lenovo/Downloads/unsupervisedL_forRAG.pdf'}, page_content='**Dimensionality reduc Ɵon** methods also play a cri Ɵcal role in data preprocessing, as they allow \\\\nmachine learning algorithms to perform eﬃciently on complex datasets by reducing unnecessary \\\\nnoise and redundancy. In genomics, for example, data o Ōen contains thousands of gene Ɵc markers, \\\\nwhich can be computa Ɵonally prohibi Ɵve. Dimensionality reduc Ɵon methods like PCA help by \\\\ncondensing the data into a manageable form that retains essen Ɵal informa Ɵon, thus facilita Ɵng the \\\\ndiscovery of underlying pa Ʃerns in biological data. Addi Ɵonally, in image recogni Ɵon, dimensionality \\\\nreducƟon aids in compressing large pixel -based data, which not only speeds up the training process \\\\nfor models but also improves the model\\\\'s generaliza Ɵon by removing irrelevant  features. \\\\n \\\\nDespite their advantages, unsupervised learning techniques have limita Ɵons. For clustering \\\\nalgorithms, deﬁning \\\"similarity\\\" is inherently subjec Ɵve and varies based on the speciﬁc data and the \\\\nintended applica Ɵon. For instance, the Euclidean distance metric used in k-means may not be \\\\nsuitable for all types of data, especially in high-dimensional or sparse datasets. Clustering techniques \\\\nare also sensi Ɵve to data scaling; if features are not standardized, clusters may be biased toward \\\\nfeatures with lar ger values. Addi Ɵonally, some clustering algorithms, like k -means, assume that \\\\nclusters are spherical and evenly distributed, which is o Ōen not the case in real -world data. These \\\\nlimitaƟons require careful data preprocessing and parameter tuning to ensu re that the results are \\\\nmeaningful. \\\\n \\\\nAnother challenge with unsupervised learning is the **interpretability of results**. Unlike supervised \\\\nlearning, where model predic Ɵons can be directly compared to true labels, the output of \\\\nunsupervised learning algorithms can be ambiguous and harder to explain. For instance, when \\\\nclustering data, it is o Ōen necessary to examine each cluster’s characteris Ɵcs manually to interpret \\\\nthe results, which can be Ɵme-consuming for large datasets. In dimensionality reduc Ɵon, while \\\\ntechniques like PCA provide insights into the principal components, they do not always reveal the \\\\nspeciﬁc variables responsible for variance, making it challenging to link the results back to \\\\ninterpretable features. \\\\n \\\\nHowever, advances in unsupervised learning con Ɵnue to address these challenges. Hybrid \\\\napproaches that combine supervised and unsupervised learning, such as **semi-supervised \\\\nlearning**, allow models to learn from both labeled and unlabeled data. This app roach is par Ɵcularly \\\\nbeneﬁcial in scenarios where a small por Ɵon of labeled data is available but insuﬃcient for fully \\\\nsupervised training. Addi Ɵonally, new clustering algorithms, such as **density -based spa Ɵal \\\\nclustering of applica Ɵons with noise (DBSCAN)**, can form arbitrarily shaped clusters and iden Ɵfy \\\\noutliers, providing more ﬂexibility than tradi Ɵonal k-means clustering. DBSCAN is especially useful for \\\\ndetecƟng clusters in data with noise, as it separates dense clusters from sparser regio ns in the \\\\ndataset. \\\\n \\\\nUnsupervised learning is also evolving through the integra Ɵon of deep learning techniques. \\\\n**Autoencoders**, for example, are neural networks designed for dimensionality reduc Ɵon. These \\\\nnetworks are trained to compress data into a lower-dimensional repre sentaƟon and then reconstruct \\\\nthe data from this compressed form. Autoencoders have become valuable in anomaly detec Ɵon and \\\\nimage processing, where they are used to learn compressed representa Ɵons of images or detect')]\\n\\nQuestion: what is K means algorithm?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatGroq] [1.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"According to the provided context, K-means clustering is a popular clustering technique in unsupervised learning. The \\\"k\\\" in k-means refers to the number of clusters into which the data is divided. The process begins with the algorithm selecting \\\"k\\\" random points as the initial centroids, which serve as the center of each cluster. Each data point is then assigned to the nearest centroid, forming a cluster. After assigning all data points, the centroids are recalculated based on the mean of the points within each cluster. This iterative process continues until the centroids no longer change significantly, indicating that the clusters are stable. K-means clustering is widely used due to its simplicity and efficiency, making it suitable for large datasets. However, it has limitations, including sensitivity to the initial choice of centroids and difficulty in determining the optimal number of clusters, often requiring methods like the elbow method to assess cluster validity.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"According to the provided context, K-means clustering is a popular clustering technique in unsupervised learning. The \\\"k\\\" in k-means refers to the number of clusters into which the data is divided. The process begins with the algorithm selecting \\\"k\\\" random points as the initial centroids, which serve as the center of each cluster. Each data point is then assigned to the nearest centroid, forming a cluster. After assigning all data points, the centroids are recalculated based on the mean of the points within each cluster. This iterative process continues until the centroids no longer change significantly, indicating that the clusters are stable. K-means clustering is widely used due to its simplicity and efficiency, making it suitable for large datasets. However, it has limitations, including sensitivity to the initial choice of centroids and difficulty in determining the optimal number of clusters, often requiring methods like the elbow method to assess cluster validity.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 182,\n",
      "                \"prompt_tokens\": 4006,\n",
      "                \"total_tokens\": 4188,\n",
      "                \"completion_time\": 0.52,\n",
      "                \"prompt_time\": 0.170120106,\n",
      "                \"queue_time\": 0.0007549119999999965,\n",
      "                \"total_time\": 0.690120106\n",
      "              },\n",
      "              \"model_name\": \"llama3-70b-8192\",\n",
      "              \"system_fingerprint\": \"fp_87cbfbbc4d\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a2bda37c-28f3-4ed8-bda3-d2c8c6e80a52-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 4006,\n",
      "              \"output_tokens\": 182,\n",
      "              \"total_tokens\": 4188\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 182,\n",
      "      \"prompt_tokens\": 4006,\n",
      "      \"total_tokens\": 4188,\n",
      "      \"completion_time\": 0.52,\n",
      "      \"prompt_time\": 0.170120106,\n",
      "      \"queue_time\": 0.0007549119999999965,\n",
      "      \"total_time\": 0.690120106\n",
      "    },\n",
      "    \"model_name\": \"llama3-70b-8192\",\n",
      "    \"system_fingerprint\": \"fp_87cbfbbc4d\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the provided context, K-means clustering is a popular clustering technique in unsupervised learning. The \\\"k\\\" in k-means refers to the number of clusters into which the data is divided. The process begins with the algorithm selecting \\\"k\\\" random points as the initial centroids, which serve as the center of each cluster. Each data point is then assigned to the nearest centroid, forming a cluster. After assigning all data points, the centroids are recalculated based on the mean of the points within each cluster. This iterative process continues until the centroids no longer change significantly, indicating that the clusters are stable. K-means clustering is widely used due to its simplicity and efficiency, making it suitable for large datasets. However, it has limitations, including sensitivity to the initial choice of centroids and difficulty in determining the optimal number of clusters, often requiring methods like the elbow method to assess cluster validity.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [3.27s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"According to the provided context, K-means clustering is a popular clustering technique in unsupervised learning. The \\\"k\\\" in k-means refers to the number of clusters into which the data is divided. The process begins with the algorithm selecting \\\"k\\\" random points as the initial centroids, which serve as the center of each cluster. Each data point is then assigned to the nearest centroid, forming a cluster. After assigning all data points, the centroids are recalculated based on the mean of the points within each cluster. This iterative process continues until the centroids no longer change significantly, indicating that the clusters are stable. K-means clustering is widely used due to its simplicity and efficiency, making it suitable for large datasets. However, it has limitations, including sensitivity to the initial choice of centroids and difficulty in determining the optimal number of clusters, often requiring methods like the elbow method to assess cluster validity.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "user_input = ChainInput(question=\"what is K means algorithm?\")\n",
    "langchain.debug=True # u can turn this off\n",
    "result2 = chain.invoke(user_input.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4dde733a-78f3-42f1-850c-06e4cb03b55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, K-means clustering is a popular clustering technique in unsupervised learning. The \"k\" in k-means refers to the number of clusters into which the data is divided. The process begins with the algorithm selecting \"k\" random points as the initial centroids, which serve as the center of each cluster. Each data point is then assigned to the nearest centroid, forming a cluster. After assigning all data points, the centroids are recalculated based on the mean of the points within each cluster. This iterative process continues until the centroids no longer change significantly, indicating that the clusters are stable. K-means clustering is widely used due to its simplicity and efficiency, making it suitable for large datasets. However, it has limitations, including sensitivity to the initial choice of centroids and difficulty in determining the optimal number of clusters, often requiring methods like the elbow method to assess cluster validity.\n"
     ]
    }
   ],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304bfc81-f7a4-47a5-ac93-e19b86c8c094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1840b3-88c5-4e94-88d7-cd2bf4edb060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
